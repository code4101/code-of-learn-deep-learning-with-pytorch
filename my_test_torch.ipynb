{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Tensor 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[2., 3.],\n",
      "        [4., 8.],\n",
      "        [7., 9.]])\n",
      "a.size(): torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.Tensor([[2, 3], [4, 8], [7, 9]])  # 默认是FloatTensor类型\n",
    "print(f'a: {a}')\n",
    "print(f'a.size(): {a.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 8],\n",
       "        [7, 9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([[2, 3], [4, 8], [7, 9]])  # 指定类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9545, -0.2745],\n",
       "        [ 1.5934, -0.1374],\n",
       "        [ 0.3876, -1.0731]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((3, 2))  # 正态分布随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2., 100.],\n",
       "        [  4.,   8.],\n",
       "        [  7.,   9.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, 1] = 100  # 修改元素值\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2., 100.],\n",
       "       [  4.,   8.],\n",
       "       [  7.,   9.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()  # 转numpy.array类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "e = np.array([[2,3], [4,5]])\n",
    "f = torch.from_numpy(e)  # array转torch张量\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.float()  # 转成 FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()  # 是否可以调用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2., 100.],\n",
       "        [  4.,   8.],\n",
       "        [  7.,   9.]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = a.cuda()  # 把变量a转成cuda数据类型放大gpu上，需要定义一个新变量存储\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Variable / autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y= tensor([[25.]], grad_fn=<AddBackward0>)\n",
      "dw= tensor([[1., 2., 3.]])\n",
      "dx= tensor([[2.],\n",
      "        [3.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# 输出值只有一个的aotograd\n",
    "w = Variable(torch.Tensor([2, 3, 4]).reshape((1,3)), requires_grad=True)\n",
    "x = Variable(torch.Tensor([1, 2, 3]).reshape((3,1)), requires_grad=True)\n",
    "b = Variable(torch.Tensor([5]), requires_grad=True)\n",
    "y = torch.matmul(w, x) + b\n",
    "print(' y=', y)\n",
    "\n",
    "y.backward()\n",
    "print('dw=', w.grad)\n",
    "print('dx=', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y= tensor(40.5000, grad_fn=<MeanBackward0>)\n",
      "dw= tensor([[1.5000, 3.5000, 5.5000]])\n",
      "dx= tensor([[1.0000, 1.0000],\n",
      "        [1.5000, 1.5000],\n",
      "        [2.0000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 多输出值：可以求平均值后autograd\n",
    "w.grad.zero_()\n",
    "x = Variable(torch.Tensor([[1, 2], [3, 4], [5, 6]]), requires_grad=True)  # 3*2\n",
    "y = torch.mean(torch.matmul(w, x) + b)\n",
    "print(' y=', y)\n",
    "\n",
    "y.backward()\n",
    "print('dw=', w.grad)\n",
    "print('dx=', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y= tensor([[36., 45.]], grad_fn=<AddBackward0>)\n",
      "dw= tensor([[ 3.,  7., 11.]])\n",
      "dx= tensor([[2., 2.],\n",
      "        [3., 3.],\n",
      "        [4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# 多输出值：也可以输出的每个维度单独求梯度，最后求和\n",
    "w.grad.zero_()  # 清除已有的梯度值\n",
    "x.grad.zero_()\n",
    "y = torch.matmul(w, x) + b  # 1*2\n",
    "print(' y=', y)\n",
    "\n",
    "# 因为y的值不只一个，需要每个独立推回去后叠加；这里也可以不用ones，自定义每个维度权重\n",
    "y.backward(torch.ones_like(y))\n",
    "print('dw=', w.grad)\n",
    "print('dx=', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3f4764b47b06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rose_points(m, nclass=2, diameter=4, disturbance=0.2, seed=None):\n",
    "    \"\"\" 玫瑰图的坐标数据（一般用于造测试数据）\n",
    "    :param m: 点数量，样本数\n",
    "    :param nclass: 类别数，默认二分类nclass=2\n",
    "    :class_petals: （该参数废弃，因为并不能要多少给多少，有个限制，所以不妨限制死，每种4个花瓣）每一类的花瓣数\n",
    "    :param diameter: 极径长度\n",
    "    :param disturbance: 随机扰动的程度\n",
    "    :param seed: 随机数种子\n",
    "    :return: 两个np.array矩阵 X, Y\n",
    "        X.shape -> (m, 2)，每一行是每个点的横纵坐标\n",
    "        Y.shape -> (m, 1)，用0、1、2...的值标记类别\n",
    "        \n",
    "    ref: https://en.wikipedia.org/wiki/Rose_(mathematics)\n",
    "    \"\"\"\n",
    "    from math import pi\n",
    "    # 1 参数计算\n",
    "    if seed: np.random.seed(seed)\n",
    "    n = int(m / nclass) # 每一类的点的个数\n",
    "    X = np.zeros((m, 2))\n",
    "    Y = np.zeros((m, 1), dtype='uint8') # label 向量，0 表示红色，1 表示蓝色\n",
    "    \n",
    "    alpha = 2 * pi / nclass  # 每一个花瓣的旋转角度\n",
    "    \n",
    "    # 2 生成点\n",
    "    for j in range(nclass):\n",
    "        ix = range(n*j, n*(j+1))\n",
    "        t = np.linspace(j*alpha, (j+1)*alpha, n) + np.random.randn(n)*disturbance  # theta\n",
    "        r = diameter*np.sin(2*nclass*t) + np.random.randn(n)*disturbance  # radius\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        Y[ix] = j\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: rose_points\n",
    "X, Y = rose_points(400, 3, disturbance=0, seed=1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y[:, 0], cmap=plt.cm.Spectral)  # https://matplotlib.org/tutorials/colors/colormaps.html?highlight=colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, x, y):\n",
    "    \"\"\" 可视化决策边界\n",
    "    :param model: 预测X值的模型，输入x，返回(m*1)的yhat\n",
    "    :param x: (m样本*n特征)的x\n",
    "    :param y: (m*1)的实际标签\n",
    "    \"\"\"\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y.reshape(-1), s=40, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class module_net(nn.Module):\n",
    "    def __init__(self, num_input, num_hidden, num_output):\n",
    "        \"\"\"\n",
    "        TODO 这个层数设置应该可以写的更灵活一些的吧~~\n",
    "        \"\"\"\n",
    "        super(module_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(num_input, num_hidden)\n",
    "        self.layer2 = nn.Tanh()\n",
    "        self.layer3 = nn.Linear(num_hidden, num_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "    def train(self, x, y, times, print_interval=None):\n",
    "        \"\"\"\n",
    "        TODO 有些训练方法是独立于模型的，获取应该封装在类外\n",
    "        TODO nn.Module本来就有train，最好不要同名覆盖\n",
    "        \"\"\"\n",
    "        # 定义优化器\n",
    "        optim = torch.optim.SGD(mo_net.parameters(), 1.)\n",
    "        # 定义损失函数\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        # 训练\n",
    "        for e in range(times):\n",
    "            out = self.forward(Variable(x))\n",
    "            loss = criterion(out, Variable(y))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            if print_interval and (e + 1) % print_interval == 0:\n",
    "                print('epoch: {}, loss: {}'.format(e+1, loss.data))\n",
    "\n",
    "                \n",
    "start = time.time()\n",
    "mo_net = module_net(2, 4, 1)\n",
    "# 数据\n",
    "x, y = rose_points(400, seed=1)\n",
    "mo_net.train(torch.Tensor(x), torch.Tensor(y), 1000, 100)\n",
    "print(f'During Time: {time.time() - start:.3f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
